{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries and modules\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import utils as np_utils\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "IMAGE_HEIGHT = 28\n",
    "IMAGE_WIDTH = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy Function\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "# load (downloaded if needed) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CNN Model 1\n",
    "\n",
    "def CNN_1():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Add another convolutional layer\n",
    "\n",
    "def CNN_2():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Add Dropout\n",
    "\n",
    "def CNN_3():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile Model 1\n",
    "\n",
    "model1 = CNN_1()\n",
    "\n",
    "model1.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile Model 2\n",
    "\n",
    "model2 = CNN_2()\n",
    "\n",
    "model2.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile Model 3\n",
    "\n",
    "model3 = CNN_3()\n",
    "\n",
    "model3.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 80s - loss: 0.3562 - acc: 0.9046 - val_loss: 0.1288 - val_acc: 0.9627\n",
      "Epoch 2/10\n",
      " - 79s - loss: 0.1081 - acc: 0.9696 - val_loss: 0.0759 - val_acc: 0.9773\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8bd74de81193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Model 1 Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 1 Train\n",
    "model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.71\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(X_test, y_test, model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 277s - loss: 0.4237 - acc: 0.8670 - val_loss: 0.0757 - val_acc: 0.9774\n",
      "Epoch 2/10\n",
      " - 263s - loss: 0.1636 - acc: 0.9527 - val_loss: 0.0521 - val_acc: 0.9816\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-248c9f6fcc97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Model 3 Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hobin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model 3 Train\n",
    "model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.00999999999999\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(X_test, y_test, model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3.save('mnistClassifier.h5')  # creates a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieves images from path\n",
    "\n",
    "def get_images(path):\n",
    "    \n",
    "    images = []\n",
    "    filenames = glob.glob(path)\n",
    "\n",
    "    i = 0\n",
    "    for f in filenames:\n",
    "        image = Image.open(f).convert('L')\n",
    "        image = image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "        images.append(np.array(image))\n",
    "        i += 1\n",
    "\n",
    "    print(i)\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "    images = images.reshape(i, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]]\n",
      "10160\n",
      "(10160, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Get labels for 2\n",
    "\n",
    "path = \"./digit_data\"\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "#new path of camera dir\n",
    "parentDir = os.path.abspath(path)\n",
    "new_dir = parentDir + \"/images2/labels\"\n",
    "\n",
    "with open(new_dir) as f:\n",
    "    labels_2 = f.readlines()\n",
    "\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "labels_2 = [x.strip() for x in labels_2]\n",
    "\n",
    "train_labels_2 = np.array(labels_2)\n",
    "train_labels_2 = np_utils.to_categorical(train_labels_2, NUM_CLASSES)\n",
    "\n",
    "print(train_labels_2)\n",
    "\n",
    "# Get images\n",
    "images_2 = get_images('./digits/images2/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.734251968503937\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of non-MNIST dataset\n",
    "\n",
    "print(accuracy(images_2, train_labels_2, model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.22564170492\n",
      "Test accuracy: 0.097342519685\n"
     ]
    }
   ],
   "source": [
    "score = model3.evaluate(images_2, train_labels_2, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieves images from path\n",
    "# Inverts images in black and white\n",
    "\n",
    "def get_images_inverted(path):\n",
    "    \n",
    "    images = []\n",
    "    filenames = glob.glob(path)\n",
    "\n",
    "    i = 0\n",
    "    for f in filenames:\n",
    "        image = Image.open(f).convert('L')\n",
    "        image = image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "        images.append(np.array(image))\n",
    "        i += 1\n",
    "\n",
    "    print(i)\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "    images = images.reshape(i, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    images = 1 - images\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Invert the image because model was trained in white background with black digits\n",
    "\n",
    "#Test image is from hockey scoreboard, where the background is black and the digit is white\n",
    "zero = get_images('./digit_data/0/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "p = model3.predict(zero, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.92105808e-04   6.98830845e-05   8.35189785e-05 ...,   1.60068218e-02\n",
      "    3.39768507e-04   9.78926361e-01]\n",
      " [  3.22699244e-03   3.50150949e-04   2.59005959e-04 ...,   1.79794058e-02\n",
      "    7.10748543e-04   9.67356741e-01]\n",
      " [  1.76685214e-01   6.83412980e-03   7.02841282e-02 ...,   1.21143445e-01\n",
      "    6.25763601e-03   3.95483106e-01]\n",
      " ..., \n",
      " [  9.97914493e-01   3.12768123e-08   2.91453962e-05 ...,   2.13054427e-05\n",
      "    5.35588333e-06   1.87039823e-05]\n",
      " [  9.98471916e-01   6.60541701e-08   3.06019465e-05 ...,   6.21182626e-05\n",
      "    7.56929239e-06   4.27768864e-05]\n",
      " [  9.99828339e-01   4.38188792e-08   4.76524838e-06 ...,   1.14821623e-05\n",
      "    1.86271718e-05   1.72896143e-05]]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 9 9 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 9 0\n",
      " 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 6 0 0 0 9 0 0 0 6 0 0 0 0 0 0 9 6 0 0 0 0\n",
      " 0 0 6 0 0 9 0 0 0 0 6 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 9 0 0 0 0 0 9 0\n",
      " 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0\n",
      " 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 9 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(p,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Invert the image because model was trained in white background with black digits\n",
    "\n",
    "#Test image is from hockey scoreboard, where the background is black and the digit is white\n",
    "one = get_images('./digit_data/1/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "p_1 = model3.predict(one, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04037897  0.09269956  0.15313569 ...,  0.11371574  0.06447284\n",
      "   0.1135007 ]\n",
      " [ 0.03546046  0.09483983  0.10690622 ...,  0.03852637  0.10558296\n",
      "   0.12389571]\n",
      " [ 0.03433665  0.02188913  0.2279204  ...,  0.00779748  0.09645531\n",
      "   0.0360094 ]\n",
      " ..., \n",
      " [ 0.00676308  0.18148786  0.11468335 ...,  0.58250123  0.02993724\n",
      "   0.00590438]\n",
      " [ 0.00370861  0.31655335  0.06364731 ...,  0.49851999  0.014361\n",
      "   0.00504355]\n",
      " [ 0.00139787  0.35825115  0.01933993 ...,  0.53113043  0.02169169\n",
      "   0.01742107]]\n"
     ]
    }
   ],
   "source": [
    "print(p_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 6 6 7 7 1 4 1 7 7 7 7 4 2 4 4 7 7 7 7 4 4 4 7 3 7 7 7 4 4 4 7 7 7 7 1 4\n",
      " 4 4 7 7 7 7 4 4 4 3 9 9 9 9 9 9 9 9 9 9 6 9 9 9 9 9 9 9 9 9 9 6 9 9 9 9 9\n",
      " 9 9 9 9 9 6 9 9 9 9 9 2 3 6 1 3 6 6 6 2 3 1 3 6 6 6 6 2 3 1 1 8 8 3 1 2 1\n",
      " 1 1 8 8 3 1 1 1 1 3 8 8 3 1 1 1 1 8 8 3 1 1 1 1 1 8 8 3 1 1 1 3 7 7 7 7 1\n",
      " 4 1 7 7 7 6 7 1 4 1 7 7 7 7 1 4 6 1 7 7 7 7 1 4 1 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(p_1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Invert the image because model was trained in white background with black digits\n",
    "\n",
    "#Test image is from hockey scoreboard, where the background is black and the digit is white\n",
    "two = get_images('./digit_data/2/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "p_2 = model3.predict(two, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 2 2 2 2 2 2 0 0 0 0 0 2 7 7 0 0 0 0 0 7 7 0 2 0 0 0 0 7 7 0 0 0 0 4 0\n",
      " 7 7 0 0 0 0 0 7 7 3 0 0 5 0 0 0 0 0 0 5 2 0 0 0 0 0 0 5 0 0 0 2 0 0 0 5 0\n",
      " 0 0 0 0 0 2 5 0 0 0 0 2 2 2 4 3 2 2 2 2 2 4 3 2 2 2 2 2 2 4 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(p_2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[2 4 2 3 3 3 3 3 2 3 3 2 3 1 8 3 2 3 3 2 3 8 3 2 1 3 3 2 3 8 3 2 3 3 2 1 3\n",
      " 8 3 2 3 3 2 3 8 3 2 0 0 0 0 2 2 2 0 0 0 4 0 2 2 2 0 0 0 0 2 2 1 2 0 0 0 0\n",
      " 2 2 2 0 0 2 0 0 2 2 2 1 1 1 1 2 4 1 2 1 1 1 2 4 2 1 2 1 1 1 3 3 3 2 3 1 3\n",
      " 2 3 3 3 2 3 3 2 3 1 3 3 2 3 3 2 3 3 3 2 1 3 3 2 3 3 3 2 3 3 2 2 3 3 3 3 3\n",
      " 3 3 3 3 3 4 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "three = get_images('./digit_data/3/*.jpg')\n",
    "p_3 = model3.predict(three, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[4 4 2 2 2 2 2 2 2 8 8 8 8 6 8 8 2 8 8 8 8 8 8 2 6 8 8 8 8 8 8 2 8 8 8 4 8\n",
      " 8 8 2 8 8 8 8 8 8 4 0 5 5 1 0 9 9 0 5 5 4 1 0 9 9 0 5 5 1 0 9 2 9 0 5 5 1\n",
      " 0 9 9 0 5 2 5 1 0 9 9 6 6 2 4 4 4 2 2 6 6 4 4 4 2 2 2 6 6 4 1 8 3 1 1 6 2\n",
      " 6 1 8 3 1 1 2 6 1 6 8 3 1 1 2 6 1 8 3 1 4 1 2 6 1 8 3 1 1 2 6 4 2 2 2 2 2\n",
      " 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "four = get_images('./digit_data/4/*.jpg')\n",
    "p_4 = model3.predict(four, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_4,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[3 7 2 5 5 5 5 5 3 3 5 5 5 3 5 8 3 3 5 5 5 5 8 3 2 3 5 5 5 5 8 3 3 5 5 3 5\n",
      " 5 8 3 3 5 5 5 5 8 3 8 8 2 2 2 8 8 8 8 2 7 2 2 8 8 8 8 2 2 2 8 2 8 8 8 2 2\n",
      " 2 8 8 8 8 2 2 2 2 8 8 3 2 2 3 3 7 2 2 3 2 3 3 7 2 2 2 3 2 3 5 5 3 3 3 3 9\n",
      " 5 5 5 3 3 3 9 5 5 2 5 3 3 3 9 5 5 5 3 3 3 3 9 5 5 5 3 3 3 9 5 3 5 5 5 5 5\n",
      " 5 5 5 5 5 7 5 5 5 5 5 5 5 5 5 5 2 5 5 5 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "five = get_images('./digit_data/5/*.jpg')\n",
    "p_5 = model3.predict(five, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[2 2 2 6 0 6 6 6 8 8 8 6 8 2 8 8 8 8 8 6 8 8 8 8 1 8 8 6 8 8 8 8 8 8 6 9 8\n",
      " 8 8 8 8 8 6 8 8 8 2 8 8 1 8 8 8 8 8 8 1 2 8 8 8 8 8 8 1 8 8 8 2 8 8 8 1 8\n",
      " 8 8 8 8 8 2 1 8 8 8 8 2 1 2 9 2 2 2 2 2 1 9 2 2 2 2 2 2 1 9 9 8 3 3 3 2 9\n",
      " 9 9 8 3 3 3 9 9 9 1 8 3 3 3 9 9 9 8 3 3 9 3 9 9 9 8 3 3 3 9 9 2 6 6 6 0 6\n",
      " 6 6 6 6 6 2 0 6 6 6 6 6 6 0 6 6 2 6 6 6 6 0 6 6 6 6 6 0]\n"
     ]
    }
   ],
   "source": [
    "six = get_images('./digit_data/6/*.jpg')\n",
    "p_6 = model3.predict(six, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_6,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[7 7 6 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 6 7 7 7 7 7 7 7 7 7 7 6 7\n",
      " 7 7 7 7 7 7 7 7 7 7 7 7 7 9 9 9 9 7 7 7 7 9 9 9 9 7 7 7 9 9 9 6 9 7 7 7 9\n",
      " 9 9 9 7 7 6 7 9 9 9 9 6 6 6 6 7 7 6 6 6 6 6 7 7 6 6 6 6 6 6 2 2 2 0 0 6 2\n",
      " 6 2 2 2 0 0 2 6 2 6 2 2 0 0 2 6 2 2 2 0 6 0 2 6 2 2 2 0 0 2 6 7 2 2 7 7 7\n",
      " 7 7 2 2 7 7 7 7 7 7 2 2 7 7 7 7 6 7 2 2 7 7 7 7 7 2 2 7]\n"
     ]
    }
   ],
   "source": [
    "seven = get_images('./digit_data/7/*.jpg')\n",
    "p_7 = model3.predict(seven, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_7,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[2 2 2 8 8 8 8 8 8 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 1 8 8 8 8 8 8 8 8 8 8 1 8\n",
      " 8 8 8 8 8 8 8 8 8 2 8 1 1 6 6 1 8 8 1 1 2 6 6 1 8 8 1 1 6 6 1 2 8 8 1 1 6\n",
      " 6 1 8 8 1 2 1 6 6 1 8 2 1 2 1 2 2 2 2 2 1 1 2 2 2 2 2 2 1 1 2 3 3 3 3 2 3\n",
      " 3 2 3 3 3 3 3 3 2 1 3 3 3 3 3 3 2 3 3 3 1 3 3 3 2 3 3 3 3 3 3 2 8 8 8 8 8\n",
      " 8 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 2 8 8 8 8 8 8 8 8 8 8 8]\n"
     ]
    }
   ],
   "source": [
    "eight = get_images('./digit_data/8/*.jpg')\n",
    "p_8 = model3.predict(eight, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_8,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "(176, 28, 28)\n",
      "176/176 [==============================] - 0s 2ms/step\n",
      "[4 1 2 8 9 8 9 8 0 0 0 0 0 3 5 0 0 0 0 0 0 5 0 0 3 0 0 0 0 5 0 0 0 0 0 7 0\n",
      " 5 0 0 0 0 0 0 5 0 4 8 0 2 2 6 6 8 8 0 2 1 2 6 6 8 8 0 2 2 6 6 3 8 8 0 2 2\n",
      " 6 6 8 8 0 2 2 2 6 6 8 3 3 3 7 4 1 3 2 3 3 7 4 1 2 3 2 3 3 7 9 9 9 2 9 3 9\n",
      " 9 9 9 9 2 9 9 9 9 3 9 9 2 9 9 9 9 9 9 2 7 9 9 9 9 9 9 2 9 9 9 4 6 6 8 9 8\n",
      " 9 8 6 6 8 1 9 8 9 8 6 6 8 9 8 9 3 8 6 6 8 9 8 9 8 6 6 9]\n"
     ]
    }
   ],
   "source": [
    "nine = get_images('./digit_data/9/*.jpg')\n",
    "p_9 = model3.predict(nine, batch_size=32, verbose=1)\n",
    "print(np.argmax(p_9,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
