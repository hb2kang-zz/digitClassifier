{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries and modules\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras import utils as np_utils\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "# Image Dimensions\n",
    "# Can very Image sizes, based on computational complexity and accuracy of neural network\n",
    "IMAGE_WIDTH= 18\n",
    "IMAGE_HEIGHT = 18\n",
    "CHANNELS = 3\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Vary based on accuracy\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieves images from path\n",
    "\n",
    "def get_images(path):\n",
    "    \n",
    "    images = []\n",
    "    filenames = glob.glob(path)\n",
    "\n",
    "    i = 0\n",
    "    for f in filenames:\n",
    "        image = Image.open(f)\n",
    "        image = image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "        images.append(np.array(image))\n",
    "        i += 1\n",
    "\n",
    "    print(i)\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "    images = images.reshape(i, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieves images from path\n",
    "# Inverts images in black and white\n",
    "\n",
    "def get_images_inverted(path):\n",
    "    \n",
    "    images = []\n",
    "    filenames = glob.glob(path)\n",
    "\n",
    "    i = 0\n",
    "    for f in filenames:\n",
    "        image = Image.open(f)\n",
    "        image = image.resize((IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "        images.append(np.array(image))\n",
    "        i += 1\n",
    "\n",
    "    print(i)\n",
    "    images = np.array(images)\n",
    "    print(images.shape)\n",
    "    images = images.reshape(i, IMAGE_WIDTH, IMAGE_HEIGHT, 1)\n",
    "\n",
    "    images = images.astype('float32')\n",
    "    images /= 255\n",
    "    \n",
    "    images = 1 - images\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy Function\n",
    "\n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CNN Model 1\n",
    "\n",
    "def CNN_1():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Add another convolutional layer\n",
    "\n",
    "def CNN_2():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Add Dropout\n",
    "\n",
    "def CNN_3():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 1)))\n",
    "    model.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compile Model 1\n",
    "\n",
    "model1 = CNN_1()\n",
    "\n",
    "model1.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile Model 2\n",
    "\n",
    "model2 = CNN_2()\n",
    "\n",
    "model2.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile Model 3\n",
    "\n",
    "model3 = CNN_3()\n",
    "\n",
    "model3.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Get labels\n",
    "\n",
    "path = \"./digits\"\n",
    "\n",
    "#new path of camera dir\n",
    "parentDir = os.path.abspath(path)\n",
    "new_dir = parentDir + \"/images/labels\"\n",
    "\n",
    "with open(new_dir) as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "labels = [x.strip() for x in labels]\n",
    "\n",
    "train_labels = np.array(labels)\n",
    "train_labels = np_utils.to_categorical(train_labels, NUM_CLASSES)\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10160\n",
      "(10160, 18, 18)\n"
     ]
    }
   ],
   "source": [
    "# Get images\n",
    "images = get_images('./digits/images/*.png')\n",
    "\n",
    "# Separate training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8128, 18, 18, 1)\n",
      "(2032, 18, 18, 1)\n",
      "(8128, 10)\n",
      "(2032, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#show image\n",
    "img = X_train[0] * 255\n",
    "img = Image.fromarray(img.reshape(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "### Based on the training session, the validation accuracy stays consistent while the training accuracy increases. This is an exmaple of overfitting, where the model starts to memorize or \"learn\" the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6502 samples, validate on 1626 samples\n",
      "Epoch 1/10\n",
      "6502/6502 [==============================] - 9s 1ms/step - loss: 2.3071 - acc: 0.0972 - val_loss: 2.3044 - val_acc: 0.0910\n",
      "Epoch 2/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.2995 - acc: 0.1129 - val_loss: 2.3021 - val_acc: 0.1076\n",
      "Epoch 3/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.2916 - acc: 0.1269 - val_loss: 2.3045 - val_acc: 0.1046\n",
      "Epoch 4/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.2777 - acc: 0.1381 - val_loss: 2.3176 - val_acc: 0.1095\n",
      "Epoch 5/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.2570 - acc: 0.1587 - val_loss: 2.3153 - val_acc: 0.1132\n",
      "Epoch 6/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.2356 - acc: 0.1678 - val_loss: 2.3324 - val_acc: 0.1039\n",
      "Epoch 7/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.2098 - acc: 0.1824 - val_loss: 2.3482 - val_acc: 0.1039\n",
      "Epoch 8/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.1833 - acc: 0.1975 - val_loss: 2.3600 - val_acc: 0.0966\n",
      "Epoch 9/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.1565 - acc: 0.2122 - val_loss: 2.3675 - val_acc: 0.0984\n",
      "Epoch 10/10\n",
      "6502/6502 [==============================] - 7s 1ms/step - loss: 2.1269 - acc: 0.2301 - val_loss: 2.3899 - val_acc: 0.1039\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138281f7710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 1 Train\n",
    "model1.fit(X_train, y_train, validation_split = 0.2, epochs = 10, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6502 samples, validate on 1626 samples\n",
      "Epoch 1/10\n",
      "6502/6502 [==============================] - 14s 2ms/step - loss: 2.3051 - acc: 0.0954 - val_loss: 2.3025 - val_acc: 0.1064\n",
      "Epoch 2/10\n",
      "6502/6502 [==============================] - 12s 2ms/step - loss: 2.3015 - acc: 0.1086 - val_loss: 2.3063 - val_acc: 0.0947\n",
      "Epoch 3/10\n",
      "6502/6502 [==============================] - 12s 2ms/step - loss: 2.2982 - acc: 0.1180 - val_loss: 2.3094 - val_acc: 0.0978\n",
      "Epoch 4/10\n",
      "6502/6502 [==============================] - 13s 2ms/step - loss: 2.2889 - acc: 0.1313 - val_loss: 2.3064 - val_acc: 0.1138\n",
      "Epoch 5/10\n",
      "6502/6502 [==============================] - 12s 2ms/step - loss: 2.2713 - acc: 0.1467 - val_loss: 2.3278 - val_acc: 0.0972\n",
      "Epoch 6/10\n",
      "6502/6502 [==============================] - 12s 2ms/step - loss: 2.2373 - acc: 0.1701 - val_loss: 2.3321 - val_acc: 0.1101\n",
      "Epoch 7/10\n",
      "6502/6502 [==============================] - 12s 2ms/step - loss: 2.1895 - acc: 0.1953 - val_loss: 2.3930 - val_acc: 0.1070\n",
      "Epoch 8/10\n",
      "6502/6502 [==============================] - 14s 2ms/step - loss: 2.1152 - acc: 0.2319 - val_loss: 2.4363 - val_acc: 0.0984\n",
      "Epoch 9/10\n",
      "6502/6502 [==============================] - 13s 2ms/step - loss: 2.0199 - acc: 0.2773 - val_loss: 2.4804 - val_acc: 0.1169\n",
      "Epoch 10/10\n",
      "6502/6502 [==============================] - 13s 2ms/step - loss: 1.9149 - acc: 0.3181 - val_loss: 2.5438 - val_acc: 0.1113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a9d8d29748>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2 Train\n",
    "model2.fit(X_train, y_train, validation_split = 0.2, epochs = 10, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5689 samples, validate on 2439 samples\n",
      "Epoch 1/10\n",
      "5689/5689 [==============================] - 13s 2ms/step - loss: 2.3103 - acc: 0.0991 - val_loss: 2.3027 - val_acc: 0.1025\n",
      "Epoch 2/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.3026 - acc: 0.1004 - val_loss: 2.3031 - val_acc: 0.0992\n",
      "Epoch 3/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.3013 - acc: 0.1107 - val_loss: 2.3039 - val_acc: 0.1029\n",
      "Epoch 4/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.3014 - acc: 0.1081 - val_loss: 2.3034 - val_acc: 0.1009\n",
      "Epoch 5/10\n",
      "5689/5689 [==============================] - 11s 2ms/step - loss: 2.2988 - acc: 0.1128 - val_loss: 2.3037 - val_acc: 0.1050\n",
      "Epoch 6/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2982 - acc: 0.1139 - val_loss: 2.3047 - val_acc: 0.1000\n",
      "Epoch 7/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2958 - acc: 0.1144 - val_loss: 2.3054 - val_acc: 0.1009\n",
      "Epoch 8/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2905 - acc: 0.1310 - val_loss: 2.3098 - val_acc: 0.1046\n",
      "Epoch 9/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2880 - acc: 0.1313 - val_loss: 2.3084 - val_acc: 0.1013\n",
      "Epoch 10/10\n",
      "5689/5689 [==============================] - 11s 2ms/step - loss: 2.2821 - acc: 0.1341 - val_loss: 2.3084 - val_acc: 0.0996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a9e0f75da0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3 Train\n",
    "model3.fit(X_train, y_train, validation_split = 0.3, epochs = 10, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b7ce7b76deb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#new path of camera dir\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mparentDir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mnew_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparentDir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/images2/labels\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Get labels for 2\n",
    "\n",
    "path = \"./digits\"\n",
    "\n",
    "#new path of camera dir\n",
    "parentDir = os.path.abspath(path)\n",
    "new_dir = parentDir + \"/images2/labels\"\n",
    "\n",
    "with open(new_dir) as f:\n",
    "    labels_2 = f.readlines()\n",
    "\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "labels_2 = [x.strip() for x in labels_2]\n",
    "\n",
    "train_labels_2 = np.array(labels_2)\n",
    "train_labels_2 = np_utils.to_categorical(train_labels_2, NUM_CLASSES)\n",
    "\n",
    "print(train_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get images\n",
    "images_2 = get_images('./digits/images2/*.png')\n",
    "\n",
    "# Separate training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(images_2, train_labels_2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5689 samples, validate on 2439 samples\n",
      "Epoch 1/10\n",
      "5689/5689 [==============================] - 41s 7ms/step - loss: 2.3052 - acc: 0.1020 - val_loss: 2.3033 - val_acc: 0.0943\n",
      "Epoch 2/10\n",
      "5689/5689 [==============================] - 38s 7ms/step - loss: 2.2997 - acc: 0.1213 - val_loss: 2.3071 - val_acc: 0.0984\n",
      "Epoch 3/10\n",
      "5689/5689 [==============================] - 38s 7ms/step - loss: 2.2899 - acc: 0.1325 - val_loss: 2.3117 - val_acc: 0.0935\n",
      "Epoch 4/10\n",
      "5689/5689 [==============================] - 38s 7ms/step - loss: 2.2591 - acc: 0.1575 - val_loss: 2.3306 - val_acc: 0.0992\n",
      "Epoch 5/10\n",
      "5689/5689 [==============================] - 33s 6ms/step - loss: 2.1980 - acc: 0.2007 - val_loss: 2.3810 - val_acc: 0.0923\n",
      "Epoch 6/10\n",
      "5689/5689 [==============================] - 33s 6ms/step - loss: 2.0894 - acc: 0.2515 - val_loss: 2.4547 - val_acc: 0.0984\n",
      "Epoch 7/10\n",
      "5689/5689 [==============================] - 37s 7ms/step - loss: 1.9463 - acc: 0.3101 - val_loss: 2.5902 - val_acc: 0.0914\n",
      "Epoch 8/10\n",
      "5689/5689 [==============================] - 32s 6ms/step - loss: 1.7592 - acc: 0.3818 - val_loss: 2.8060 - val_acc: 0.0910\n",
      "Epoch 9/10\n",
      "5689/5689 [==============================] - 35s 6ms/step - loss: 1.5802 - acc: 0.4512 - val_loss: 2.9287 - val_acc: 0.0988\n",
      "Epoch 10/10\n",
      "5689/5689 [==============================] - 42s 7ms/step - loss: 1.3779 - acc: 0.5272 - val_loss: 3.2376 - val_acc: 0.1009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a9cde8a470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 2 Train on different dataset\n",
    "model2.fit(X_train_2, y_train_2, validation_split = 0.3, epochs = 10, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.891732283464567\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(X_test_2, y_test_2, model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5689 samples, validate on 2439 samples\n",
      "Epoch 1/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.3085 - acc: 0.1030 - val_loss: 2.3037 - val_acc: 0.0959\n",
      "Epoch 2/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.3021 - acc: 0.1048 - val_loss: 2.3044 - val_acc: 0.0894\n",
      "Epoch 3/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.3009 - acc: 0.1148 - val_loss: 2.3053 - val_acc: 0.0906\n",
      "Epoch 4/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2983 - acc: 0.1181 - val_loss: 2.3061 - val_acc: 0.0939\n",
      "Epoch 5/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2950 - acc: 0.1194 - val_loss: 2.3078 - val_acc: 0.0873\n",
      "Epoch 6/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2906 - acc: 0.1297 - val_loss: 2.3083 - val_acc: 0.0943\n",
      "Epoch 7/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2817 - acc: 0.1404 - val_loss: 2.3116 - val_acc: 0.0931\n",
      "Epoch 8/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2734 - acc: 0.1389 - val_loss: 2.3146 - val_acc: 0.1013\n",
      "Epoch 9/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2592 - acc: 0.1526 - val_loss: 2.3202 - val_acc: 0.1021\n",
      "Epoch 10/10\n",
      "5689/5689 [==============================] - 10s 2ms/step - loss: 2.2407 - acc: 0.1629 - val_loss: 2.3310 - val_acc: 0.1046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a9e25f3be0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3 Train\n",
    "model3.fit(X_train_2, y_train_2, validation_split = 0.3, epochs = 10, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar digit and font type to scoreboard digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "# Get labels\n",
    "\n",
    "path = \"./digits\"\n",
    "\n",
    "#new path of camera dir\n",
    "parentDir = os.path.abspath(path)\n",
    "new_dir = parentDir + \"/small2/labels.txt\"\n",
    "\n",
    "with open(new_dir) as f:\n",
    "    labels = f.readlines()\n",
    "\n",
    "# remove whitespace characters like `\\n` at the end of each line\n",
    "labels = [x.strip() for x in labels]\n",
    "\n",
    "train_labels = np.array(labels)\n",
    "train_labels = np_utils.to_categorical(train_labels, NUM_CLASSES)\n",
    "\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "(78, 18, 18)\n"
     ]
    }
   ],
   "source": [
    "# Get images\n",
    "images = get_images('./digits/small2/*.png')\n",
    "\n",
    "# Separate training and testing dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43 samples, validate on 19 samples\n",
      "Epoch 1/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0782 - acc: 0.9767 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0978 - acc: 0.9767 - val_loss: 0.0059 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1105 - acc: 0.9767 - val_loss: 0.0068 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1290 - acc: 0.9767 - val_loss: 0.0116 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1750 - acc: 0.9302 - val_loss: 0.0057 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1240 - acc: 0.9767 - val_loss: 0.0069 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2715 - acc: 0.9070 - val_loss: 0.0126 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2518 - acc: 0.9302 - val_loss: 0.0127 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1462 - acc: 0.9535 - val_loss: 0.0115 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2806 - acc: 0.8837 - val_loss: 0.0118 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1472 - acc: 0.9767 - val_loss: 0.0137 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2226 - acc: 0.9070 - val_loss: 0.0141 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0487 - acc: 1.0000 - val_loss: 0.0131 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1233 - acc: 1.0000 - val_loss: 0.0084 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0430 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0206 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0650 - acc: 0.9767 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0881 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0751 - acc: 0.9767 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0670 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0910 - acc: 0.9767 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1153 - acc: 0.9767 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1196 - acc: 0.9767 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0681 - acc: 0.9767 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0378 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0643 - acc: 0.9767 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0556 - acc: 0.9767 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0624 - acc: 0.9767 - val_loss: 8.0916e-04 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0634 - acc: 1.0000 - val_loss: 5.8061e-04 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0805 - acc: 0.9767 - val_loss: 8.2669e-04 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0608 - acc: 0.9767 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - acc: 0.9767 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0591 - acc: 0.9767 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1281 - acc: 0.9302 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0970 - acc: 0.9767 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0540 - acc: 0.9767 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0672 - acc: 0.9535 - val_loss: 7.6128e-04 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0940 - acc: 0.9535 - val_loss: 4.4538e-04 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0489 - acc: 1.0000 - val_loss: 4.9050e-04 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 5.1483e-04 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 4.9669e-04 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0669 - acc: 1.0000 - val_loss: 3.5380e-04 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1919 - acc: 0.9070 - val_loss: 5.4510e-04 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0457 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1430 - acc: 0.9535 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0397 - acc: 1.0000 - val_loss: 8.0256e-04 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2289 - acc: 0.9070 - val_loss: 9.8294e-04 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0969 - acc: 0.9767 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0980 - acc: 0.9767 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1159 - acc: 0.9767 - val_loss: 0.0053 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0628 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1745 - acc: 0.8837 - val_loss: 9.9737e-04 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1069 - acc: 0.9535 - val_loss: 7.2767e-04 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0570 - acc: 0.9767 - val_loss: 5.3336e-04 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0960 - acc: 0.9535 - val_loss: 4.1449e-04 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0382 - acc: 0.9767 - val_loss: 4.4022e-04 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0243 - acc: 1.0000 - val_loss: 4.1204e-04 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0529 - acc: 1.0000 - val_loss: 2.9174e-04 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1113 - acc: 0.9535 - val_loss: 3.0093e-04 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0498 - acc: 1.0000 - val_loss: 3.4084e-04 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0668 - acc: 0.9767 - val_loss: 2.8958e-04 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0701 - acc: 0.9767 - val_loss: 3.0250e-04 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0568 - acc: 0.9767 - val_loss: 3.5173e-04 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0974 - acc: 0.9535 - val_loss: 3.1498e-04 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0923 - acc: 0.9767 - val_loss: 3.2269e-04 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0383 - acc: 1.0000 - val_loss: 5.7401e-04 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2438 - acc: 0.9302 - val_loss: 4.8174e-04 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1776 - acc: 0.9535 - val_loss: 1.4103e-04 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0345 - acc: 1.0000 - val_loss: 1.1275e-04 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1183 - acc: 0.9767 - val_loss: 1.2253e-04 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.4953e-04 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0491 - acc: 0.9767 - val_loss: 1.6009e-04 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 1.4762e-04 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0531 - acc: 0.9767 - val_loss: 1.3383e-04 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0857 - acc: 0.9535 - val_loss: 1.5646e-04 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 1.5623e-04 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1338 - acc: 0.9535 - val_loss: 4.0023e-04 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0789 - acc: 0.9535 - val_loss: 7.9486e-04 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0462 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0712 - acc: 0.9767 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1303 - acc: 0.9535 - val_loss: 9.9039e-04 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0358 - acc: 1.0000 - val_loss: 6.6956e-04 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0767 - acc: 0.9302 - val_loss: 5.9554e-04 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1746 - acc: 0.9535 - val_loss: 6.1581e-04 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0298 - acc: 1.0000 - val_loss: 6.0950e-04 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0508 - acc: 1.0000 - val_loss: 4.0331e-04 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 2.1042e-04 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0908 - acc: 0.9535 - val_loss: 1.6461e-04 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0968 - acc: 0.9767 - val_loss: 3.0988e-04 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1056 - acc: 0.9302 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0668 - acc: 0.9767 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0754 - acc: 0.9535 - val_loss: 7.9936e-04 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0541 - acc: 0.9535 - val_loss: 3.5865e-04 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1404 - acc: 0.9535 - val_loss: 7.0352e-04 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1202 - acc: 0.9302 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1316 - acc: 0.9535 - val_loss: 9.8582e-04 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 7.5418e-04 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0577 - acc: 1.0000 - val_loss: 4.5902e-04 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.0332 - acc: 1.0000 - val_loss: 2.5626e-04 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26427460d30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model 3 Train\n",
    "model3.fit(X_train, y_train, validation_split = 0.3, epochs = 100, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model3.save('digitClassifier.h5')  # creates a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('digitClassifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(1, 18, 18)\n"
     ]
    }
   ],
   "source": [
    "#Invert the image because model was trained in white background with black digits\n",
    "\n",
    "#Test image is from hockey scoreboard, where the background is black and the digit is white\n",
    "one = get_images_inverted('./digits/one/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(one, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(p,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
